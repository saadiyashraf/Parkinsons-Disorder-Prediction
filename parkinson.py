# -*- coding: utf-8 -*-
"""Parkinson.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pGgJIjFVVQR6Jzl0CU8zxJc6FEemoXr5
"""

import numpy as np
import pandas as pd 
import matplotlib
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

from google.colab import files
uploaded= files.upload()

data=pd.read_csv("Parkinson disease.csv")

## here is how the data looks like
data.head()

#To find the number of rows and columns
data.shape

#To find the data type of each column
data.info()

data.drop('name',1,inplace = True)
data.head()

#To find the number of null values in each column
data.isnull().sum()

#To find mean, count,etc ie Statistical measure 
data.describe()

#Distribution of the target column (status column)
print(data['status'].value_counts(normalize = True))
pd.value_counts(data['status']).plot(kind = "bar")

plt.figure(figsize=(30,20))
sns.heatmap(data.corr(),annot=True)

y = data['status']
X = data.drop('status',1)

print(X.shape)
print(y.shape)

def distplot(i):
  sns.displot(data[i],bins=20)

for i in X.columns:
  distplot(i)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=7)
X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.2,random_state=7)
X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2,random_state=7)
X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=0.2,random_state=7)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.preprocessing import StandardScaler
sc_x = StandardScaler()
X_train = sc_x.fit_transform(X_train) 
X_test = sc_x.transform(X_test)
  
print (X_train[0:10, :])

"""LOGISTIC REGRESSION"""

from sklearn.linear_model import LogisticRegression  
classifier= LogisticRegression(random_state=0)  
classifier.fit(X_train, y_train)

y_pred= classifier.predict(X_test)

#Creating the Confusion matrix  
from sklearn.metrics import confusion_matrix  
cm= confusion_matrix(y_test,y_pred)  
print ("Confusion Matrix : \n", cm)

from sklearn.metrics import accuracy_score
accuracy_classifier = accuracy_score(y_test, y_pred)
print ("Accuracy : ",accuracy_classifier )

#define new observation
new = [118,135,95,0.013,0.0009,0.00345,0.00546,0.01318,0.03498,0.598,0.56,0.43,0.45,0.04519,0.02189,21.342,0.4232,0.80232,-3.2342,0.31124,2.54957,0.309282]

#predict which class the new observation belongs to
classifier.predict([new])

"""RANDOM FOREST CLASSIFIER"""

#Import Random Forest Model
from sklearn.ensemble import RandomForestClassifier

rfc=RandomForestClassifier(n_estimators=100)

#Train the model using the training sets 
rfc.fit(X_train1,y_train1)

y_pred1=rfc.predict(X_test1)

#Creating the Confusion matrix  
from sklearn.metrics import confusion_matrix  
cm1= confusion_matrix(y_test1,y_pred1)  
print ("Confusion Matrix : \n", cm1)

# Model Accuracy
accuracy_rfc= accuracy_score(y_test1, y_pred1)
print("Accuracy:",accuracy_rfc)

#define new observation
new = [118,135,95,0.013,0.0009,0.00345,0.00546,0.01318,0.03498,0.598,0.56,0.43,0.45,0.04519,0.02189,21.342,0.4232,0.80232,-3.2342,0.31124,2.54957,0.309282]

#predict which class the new observation belongs to
rfc.predict([new])

"""DECISION TREE CLASSIFIER"""

from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation

# Create Decision Tree classifer object
clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train2,y_train2)

#Predict the response for test dataset
y_pred2 = clf.predict(X_test2)

# Model Accuracy
accuracy_clf= accuracy_score(y_test2, y_pred2)
print("Accuracy:",accuracy_clf)

#define new observation
new = [118,135,95,0.013,0.0009,0.00345,0.00546,0.01318,0.03498,0.598,0.56,0.43,0.45,0.04519,0.02189,21.342,0.4232,0.80232,-3.2342,0.31124,2.54957,0.309282]

#predict which class the new observation belongs to
clf.predict([new])

"""NAIVE BAYES CLASSIFIER"""

# training the model on training set
from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(X_train3, y_train3)
 
# making predictions on the testing set
y_pred3 = gnb.predict(X_test3)

# Model accuracy
accuracy_gnb = accuracy_score(y_test3, y_pred3)
print("Gaussian Naive Bayes model accuracy(in %):",accuracy_gnb )

#define new observation
new = [118,135,95,0.013,0.0009,0.00345,0.00546,0.01318,0.03498,0.598,0.56,0.43,0.45,0.04519,0.02189,21.342,0.4232,0.80232,-3.2342,0.31124,2.54957,0.309282]

#predict which class the new observation belongs to
gnb.predict([new])

accuracy_scores = {"Logistic Regression": accuracy_classifier, "Random Forest Classifier":accuracy_rfc, "Decision Tree Classifier":accuracy_clf, "Naive Bayes Classifier": accuracy_gnb}
models= list(accuracy_scores.keys())
scores= list(accuracy_scores.values())

fig = plt.figure(figsize = (10, 5))
 
# creating the bar plot
plt.bar(models, scores, color ='green',
        width = 0.4)
 
plt.xlabel("Models used")
plt.ylabel("Accuracy scores")
plt.title("Models used for prediction and their accuracy scores")
plt.show()

